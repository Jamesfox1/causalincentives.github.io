## Who we are

The Causal Incentives Working Group is a collection of researchers, interested in using causal models to understand the incentives of AI systems. We are particularly interested in applying these models to the design of safe and fair AI algorithms.


If you are interested in working on these problems, as a collaborator, visitor, or in any other capacity feel free to get in touch.

# Researchers
* **Tom Everitt**: DeepMind
* **Ryan Carey**: University of Oxford
* **Eric D. Langlois**: University of Toronto
* **Carolyn Ashurst**: Future of Humanity Institute, University of Oxford
* **Chris van Merwijk**: Future of Humanity Institute, University of Oxford
* **Lewis Hammond**: University of Oxford
* **James Fox**: University of Oxford

[with affiliation, links to each personâ€™s webpage, and link to affiliation], Pedro?, Ramana?


# Papers
**Agent Incentives: A Causal Perspective**: presents sound and complete graphical criteria for four incentive concepts: value of information, value of control, response incentives, and control incentives.
*T. Everitt\*, R. Carey\*, E. Langlois\*, P. Ortega, S. Legg*
AAAI-21

**How RL Agents Behave When Their Actions Are Modified**
**Equilibrium Refinements for Multi-Agent Influence Diagrams: Theory and Practice**
**Modeling AGI safety frameworks with causal influence diagrams**
**Reward tampering problems and solutions in reinforcement learning: A causal influence diagram perspective**
**The Incentives that Shape Behavior** [superseded by AI:ACP]
**Understanding Agent Incentives** [superseded by AI:ACP]
